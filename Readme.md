# ğŸš¦ Intelligent Traffic Signal Optimization Using Reinforcement Learning in SUMO

**Institution:** Indian Institute of Information Technology, Nagpur  
**Mentor:** Dr. Rashmi Pandhare  
**Contributors:** Saurabh Kumar â€¢ Darshan Tate â€¢ Sai Chandra Mouli  

---

## ğŸ“Œ Overview
Traffic congestion at urban intersections is worsened by static signal timers that fail to adapt to real-time vehicle flow. This project implements and compares:
- **Static Timer Controller**
- **Tabular Q-Learning RL Agent**
- **Deep Q-Network (DQN) RL Agent**

Using **SUMO simulation**, **TraCI real-time control**, and **E1 lane detectors**, the models are evaluated using standard **ITS metrics**.

---

## ğŸ§  Reinforcement Learning Design

| Component | Implementation |
|---|---|
| **State Space** | 7 values â†’ 6 lane detector counts + current signal phase |
| **Actions** | `0 = Keep phase`, `1 = Switch to next phase` |
| **Reward** | `R = âˆ’(Sum of lane queues)` |

---

## ğŸ“Š Model-Wise Statistical Analysis

---

### ğŸ”¹ Static Model â€” Queue Length Output
![Static Queue Length Graph](<images/Staticgraph.jpeg>)

- Avg Queue â‰ˆ **7.77 vehicles**
- Max Queue = **12**
- Total Delay â‰ˆ **23,000 vehicle-seconds**
- Throughput = **1929 vehicles**
- Max Travel Time = **1332 sec**

---

### ğŸ”¹ Q-Learning Model â€” Queue Length Output
![Q-Learning Queue Length Graph](<images/QGraph.jpeg>)

- Avg Queue â†“ **~38%**
- Max Queue = **8**
- Delay â†“ **~39%**
- Throughput = **2368 vehicles** (**+22% over static**)
- Travel Time â†“ **~57%**

---

### ğŸ”¹ DQN Model â€” Queue Length Output
![DQN Queue Length Graph](<images/DQNgraph.jpeg>)

- Avg Queue â†“ **~35%**
- Max Queue = **8**
- Delay â†“ **~36%**
- Throughput = **2303 vehicles**
- Travel Time â†“ **~54%**
- Most stable switching due to neural generalization

---

## â± Time Analysis Outputs (Per Model)

### ğŸŸ¡ Static Controller â€” Python Time Analysis
![Static Time Analysis Output](<images/Staticmetrics.jpeg>)

- Minimal compute cost
- No adaptation â†’ high real-world time wasted in queues

---

### ğŸŸ¢ Q-Learning Controller â€” Python Time Analysis
![Q-Learning Time Analysis Output](<images/Qmetrics.jpeg>)

- Fast Q-table lookup & updates
- Aggressive phase optimization
- Best overall system-level time savings

---

### ğŸ”µ DQN Controller â€” Python Time Analysis
![DQN Time Analysis Output](<images/DQN metrics.jpeg>)

- Includes neural inference overhead
- Still better than static due to smarter phase control
- Best worst-case congestion handling

---

## Flow Chart 
![Flow Chart](<images/NoteGPT-Flowchart-1757804082141.png>)

---

## ğŸ Conclusion
Reinforcement Learning enables **real-time adaptive signal control** with clear improvements:

![Conclusion Summary Image](<images/WhatsApp Image 2025-11-19 at 10.11.35 PM.jpg>)

- **Delay Reduction:** **35â€“40%**
- **Queue Reduction:** **â‰ˆ38%**
- **Throughput Gain:** **+22% vehicles cleared**
- **Q-Learning:** Best **average efficiency**
- **DQN:** Best **stability & worst-case travel time**
- Edge deployment feasible on **Jetson Nano / Raspberry Pi**

---

## ğŸ”® Future Scope
- Multi-intersection network
- Multi-Agent RL coordination
- CCTV + YOLO detector replacement
- Emergency & pedestrian priority
- TensorRT edge optimization

---

## ğŸ“œ License
MIT License
